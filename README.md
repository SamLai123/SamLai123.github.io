

I am Lexiao Lai 赖乐潇, a fifth-year Ph.D. student at [Columbia IEOR](https://ieor.columbia.edu/). My research is in nonconvex optimization, applied semi-algebraic geometry, and data science. I am very fortunate to be advised by [Prof. Cédric Josz](https://sites.google.com/site/cedricjosz/). Prior to Columbia, I received my Bachelor of Science in Mathematics from [the University of Hong Kong](https://www.hku.hk/).

[[Curriculum Vitae](/Lai_Lexiao_CV.pdf)]     [[Google Scholar](https://scholar.google.com/citations?user=pMOxAswAAAAJ&hl=en)]


**Email:** lexiao.lai@columbia.edu  

## Preprints and publications
1. Cédric Josz, Lexiao Lai, [Global stability of first-order methods for coercive tame functions](https://arxiv.org/abs/2308.00899), *arXiv preprint*, 2023 
2. Cédric Josz, Lexiao Lai, Xiaopeng Li, Convergence of the momentum method for semi-algebraic functions with locally Lipschitz gradients, *SIAM Journal on Optimization (to appear)*, 2023 [[preprint](https://arxiv.org/abs/2307.03331)]
3. Cédric Josz, Lexiao Lai, Sufficient conditions for instability of the subgradient method with constant step size, *SIAM Journal on Optimization (to appear)*, 2023 [[preprint](https://arxiv.org/abs/2211.14852)]
5. Cédric Josz, Lexiao Lai, [Lyapunov stability of the subgradient method with constant step size](https://doi.org/10.1007/s10107-023-01936-6), *Mathematical Programming*, 2023 [[preprint](https://arxiv.org/abs/2211.14850)]
6. Cédric Josz, Lexiao Lai, [Nonsmooth rank-one matrix factorization landscape](https://doi.org/10.1007/s11590-021-01819-9), *Optimization Letters*, 2021 [[preprint](https://arxiv.org/abs/2211.14848)]
7. Elliot Cartee, Lexiao Lai, Qianli Song, Alexander Vladimirsky, [Time-dependent surveillance-evasion games](https://eikonal-equation.github.io/TimeDependent_SEG/), *58th IEEE Conference on Decision and Control*, 2019 [[preprint](https://arxiv.org/abs/1903.01332)]

## Talks

1. INFORMS Annual Meeting, Phoenix, October 17th 2023, *Global stability of first-order methods for coercive tame functions*
2. International Congress on Industrial and Applied Mathematics, Tokyo, August 24th 2023, *Global stability of first-order methods for coercive tame functions*
3. SIAM Conference on Optimization, Seattle, June 1st 2023, *Global stability of first-order methods with constant step size for coercive tame functions*
4. CUHK SEEM Department Seminar, Hong Kong, December 8th 2022, *Lyapunov stability of the subgradient method with constant step size*
5. HKU Optimization and Machine Learning Seminar, Hong Kong, December 6th 2022, *Lyapunov stability of the subgradient method with constant step size*
6. PGMODAYS 2022, Paris, November 29th 2022, *Lyapunov stability of the subgradient method with constant step size*
7. INFORMS Annual Meeting, Indianapolis, October 17th 2022, *Lyapunov stability of the subgradient method with constant step size*

<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=150&t=tt&d=Gdy9sgTo6hTpkNAjMHFIYVC3ZGv6K11WYiFCowwOQJQ&co=2d78ad&cmo=3acc3a&cmn=ff5353&ct=ffffff"></script>
